<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">
    <link rel="stylesheet" href="../../style.css">
    <script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <title>How To Import Data with the pandas read_csv Command</title>
  </head>

<body>

<section>
<article>
<p><em>June 21, 2020</em></p>

<p>(This article originally appeared, in a slightly different form, in <a href="https://medium.com/towards-data-science/how-to-import-data-with-the-pandas-read-csv-command-a7befde122f1" target="_blank">Towards Data Science, Medium</a>.)</p>
<hr>

<p><img src="splash.jpeg" alt="Newspaper showoing stocks" class="center"></p>
Photo by <a href="https://unsplash.com/@markusspiske?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText" target="_blank">Markus Spiske</a> on Unsplash

<p>In any data analysis project, we seek to discover useful, actionable insights from a given set of data. If we're lucky, this data may already be packaged for us; if not, we may need to collect it ourselves. Either way, once the data is stored, we will need to read it into a program to perform analysis.</p>

<p>The software package pandas is often used for this purpose. It is a powerful library that works with the Python programming language. Within pandas, the tool of choice to read in data files is the ubiquitous <code>read_csv</code> function.</p>

<p>In this article, we explore the basics of pandas' <code>read_csv</code> command: header options, specifying the sub-directory, if applicable, using delimiters other than commas, identifying which column to use as the index, defining types of fields, and handling missing values.</p>

<h1>The Data</h1>
</p>As with any pandas project, we first import pandas using the standard alias <code>pd</code>. Let's also import the numerical package NumPy using its standard alias <code>np</code>.</p>

<pre class="prettyprint">
import pandas as pd
import numpy as np
</pre>

<p>For our example, let's read in stock price data. This data set lists the date of the trade, its open, close, high and low prices, the volume, and its ticker symbol.</p>

<h1>What is a .csv file?</h1>
<p>If we look at the data file in a text editor, the first few rows are as follows.</p>

<pre class="prettyprint">
date,open,high,low,close,volume,Name
2013–02–08,15.07,15.12,14.63,14.75,8407500,AAL
2013–02–11,14.89,15.01,14.26,14.46,8882000,AAL
2013–02–12,14.45,14.51,14.1,14.27,8126000,AAL
2013–02–13,14.3,14.94,14.25,14.66,10259500,AAL
2013–02–14,14.94,14.96,13.16,13.99,31879900,AAL
</pre>

<p>We see that the first row consists of the column names, also known as <e>field</e> names. This row containing the column names is called the <e>header</e>. The next rows list data corresponding to each of those fields within its row. So the first line of data has a date of 2013-02-08, an open price of $15.07 and so on. Each data point is separated from the next point by a comma, hence the name "comma separated value" (csv) file.</p>

<h1>Header options</h1>
<p>The pandas command to read the data from a file and store it in a data frame called <code>stocks_df</code> is a simple one liner.</p>

<pre class="prettyprint">
stocks_df = pd.read_csv('stocks.csv')
</pre>

<p>To make sure this command worked as expected, let’s examine the first few rows of the data frame using head.</p>

<pre class="prettyprint">
stocks_df.head()    
</pre>

<pre class="prettyprint">
    date        open    high    low     close   volume      Name
0   2013-02-08  15.07   15.12	14.63	14.75	8407500	    AL
1   2013-02-11  14.89   15.01	14.26	14.46	8882000	    AAL
2   2013-02-12  14.45   14.51	14.10	14.27	8126000	    AAL
3   2013-02-13  14.30   14.94	14.25	14.66	10259500    AAL
4   2013-02-14  14.94   14.96	13.16	13.99	31879900    AAL
</pre>

<p>You might not be interested in all the columns in the .csv file. In this case, specify which columns you want to read into the data frame by using the <code>usecols</code> option. For instance, if you're only interested in the date, the volume and the name of the stock, specify <code>usecols=['date', 'volume', 'Name']</code>.</p>

<pre class="prettyprint">
stocks_df = pd.read_csv('stocks.csv', usecols=['date', 'volume', 'Name'])
stocks_df.head()
</pre>

<pre class="prettyprint">
    date        volume      Name
0	2013-02-08	8407500	    AAL
1	2013-02-11	8882000	    AAL
2	2013-02-12	8126000	    AAL
3	2013-02-13	10259500    AAL
4	2013-02-14	31879900    AAL
</pre>
    
<p>As expected, only the columns we specified are included in the data frame.</p>

<p>By default, pandas assumes that the first row of your data is a header. Of course, not every data file has a header. For instance, suppose we have a data file without a header, as shown below.</p>

<pre class="prettyprint">
2013-02-08,15.07,15.12,14.63,14.75,8407500,AAL
2013-02-11,14.89,15.01,14.26,14.46,8882000,AAL
2013-02-12,14.45,14.51,14.1,14.27,8126000,AAL
2013-02-13,14.3,14.94,14.25,14.66,10259500,AAL
2013-02-14,14.94,14.96,13.16,13.99,31879900,AAL
</pre>

<p>If we try to read the file in as before, we will not get the results we want.</p>

<pre class="prettyprint">
stocks_df = pd.read_csv('stocks_no_header.csv')
stocks_df.head()    
</pre>

<pre class="prettyprint">
	2013-02-08	15.07	15.12	14.63	14.75	8407500     AAL
0	2013-02-11	14.89	15.01	14.26	14.46	8882000	    AAL
1	2013-02-12	14.45	14.51	14.10	14.27	8126000	    AAL
2	2013-02-13	14.30	14.94	14.25	14.66	10259500    AL
3	2013-02-14	14.94	14.96	13.16	13.99	31879900    AAL
4	2013-02-15	13.93	14.61	13.93	14.50	15628000    AAL
</pre>

</p>pandas assumes the first line is a header, and reads it in as such. In this case, this isn't what we want, since that first row is data. Fortunately, the fix is easy — just specify the option <code>header=None</code>.</p>

<pre class="prettyprint">
stocks_df = pd.read_csv('stocks_no_header.csv', header=None)
stocks_df.head()    
</pre>

<pre class="prettyprint">
    0           1       2       3       4       5           6
0	2013-02-08	15.07	15.12	14.63	14.75	8407500	    AAL
1	2013-02-11	14.89	15.01	14.26	14.46	8882000	    AAL
2	2013-02-12	14.45	14.51	14.10	14.27	8126000	    AAL
3	2013-02-13	14.30	14.94	14.25	14.66	10259500    AAL
4	2013-02-14	14.94	14.96	13.16	13.99	31879900    AAL
</pre>

<p>Now pandas has numbered the columns starting at 0. If you prefer to have named columns instead, use the names option to specify your own column names.</p>

<pre class="prettyprint">
col_names = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Ticker Symbol']
stocks_df = pd.read_csv('stocks_no_header.csv', header=None, names=col_names)
stocks_df.head()    
</pre>

<pre class="prettyprint">
	Date	Open	High	Low	Close	Volume	Ticker    Symbol
0	2013-02-08	15.07	15.12	14.63	14.75	8407500	  AAL
1	2013-02-11	14.89	15.01	14.26	14.46	8882000	  AAL
2	2013-02-12	14.45	14.51	14.10	14.27	8126000	  AAL
3	2013-02-13	14.30	14.94	14.25	14.66	10259500  AAL
4	2013-02-14	14.94	14.96	13.16	13.99	31879900  AAL   
</pre>

<h1>Directories</h1>
<p>In the example above, I saved the data file as <code>stocks.csv</code> in the same directory as my Python program. To keep things organized, it is quite common to save the data files in a sub directory. In this case, specify the data sub-directory in the read_csv statement.</p>

<pre class="prettyprint">
df = pd.read_csv('data/stocks.csv')
</pre>

<p>As before, let's check the first few rows to make sure all went well.</p>

<pre class="prettyprint">
df.head()
</pre>

<pre class="prettyprint">
    date        open    high    low     close   volume      Name
0	2013-02-08	15.07	15.12	14.63	14.75	8407500     AAL
1	2013-02-11	14.89	15.01	14.26	14.46	8882000     AAL
2	2013-02-12	14.45	14.51	14.10	14.27	8126000     AAL
3	2013-02-13	14.30	14.94	14.25	14.66	10259500    AAL
4	2013-02-14	14.94	14.96	13.16	13.99	31879900    AAL
</pre>
    
<h1>Delimiters</h1>
<p>Not all data files separate values using commas. Tabs, spaces, or any other character may be used. For instance, our data file might have been set up with semicolons instead of commas.</p>

<pre class="prettyprint">
date;open;high;low;close;volume;Name
2013-02-08;15.07;15.12;14.63;14.75;8407500;AAL
2013-02-11;14.89;15.01;14.26;14.46;8882000;AAL
2013-02-12;14.45;14.51;14.1;14.27;8126000;AAL
2013-02-13;14.3;14.94;14.25;14.66;10259500;AAL
2013-02-14;14.94;14.96;13.16;13.99;31879900;AAL
</pre>

<p>To specify a separator other than a comma, use the sep option.</p>

<pre class="prettyprint">
stocks_df = pd.read_csv('stocks_semicolon.csv', sep=';')
stocks_df.head()
</pre>

<pre class="prettyprint">
    date        open    high    low     close   volume     Name
0	2013-02-08	15.07	15.12	14.63	14.75	8407500	   AAL
1	2013-02-11	14.89	15.01	14.26	14.46	8882000	   AAL
2	2013-02-12	14.45	14.51	14.10	14.27	8126000	   AAL
3	2013-02-13	14.30	14.94	14.25	14.66	10259500   AAL
4	2013-02-14	14.94	14.96	13.16	13.99	31879900   AAL
</pre>

<h1>Specifying a column to be the index</h1>
<p>If you don’t want the default index, you may specify a column to be used as the index of the data frame. For instance, to specify the index to be the date column, use <code>index_col='date'</code>.</p>

<pre class="prettyprint">
	        open    high    low     close   volume      Name
date						
2013-02-08	15.07	15.12	14.63	14.75	8407500     AAL
2013-02-11	14.89	15.01	14.26	14.46	8882000     AAL
2013-02-12	14.45	14.51	14.10	14.27	8126000     AAL
2013-02-13	14.30	14.94	14.25	14.66	10259500    AAL
2013-02-14	14.94	14.96	13.16	13.99	31879900    AAL   
</pre>

<p>Now the date column is the index, as desired.</p>

<h1>Types</h1>
<p>Let's check the type of each column.</p>

<pre class="prettyprint">
stocks_df = pd.read_csv('stocks.csv')
stocks_df.dtypes   
</pre>

<pre class="prettyprint">
date    object
open    float64
high    float64
low     float64
close   float64
volume  int64
Name    object
dtype: object
</pre>

<p>Let's suppose we want to store the numerical data as 32 bit types to save space. To do so, set the option <code>dtype</code> to a dictionary in which the keys are the columns and the values are the desired types.</p>

<pre class="prettyprint">
types = {
    'open': np.float32,
    'high': np.float32,
    'low': np.float32,
    'close': np.float32,
    'volume': np.int32
}
stocks_df = pd.read_csv('stocks.csv', dtype=types)
stocks_df.dtypes   
</pre>

<pre class="prettyprint">
date   object
open   float32
high   float32
low    float32
close  float32
volume int32
Name   object
dtype: object   
</pre>

<p>The <code>date</code> column was read in as a generic object type, even though we know that the data consists of dates. To read the column in as date type, use the <code>parse_dates</code> option set to a list containing the index of the column.</p>

<pre class="prettyprint">
date    datetime64[ns]
open    float64
high    float64
low     float64
close   float64
volume  int64
Name    object
dtype: object  
</pre>

<h1>Missing values</h1>
<p>It is common for data to contain missing values. It is also common for missing values to be indicated by some sort of indicator, such as a question mark or the word “missing”.</p>

<pre class="prettyprint">
stocks_df = pd.read_csv('stocks_missing_data.csv')
stocks_df.head()   
</pre>

<pre class="prettyprint">
    data        open    high    low     close   volume      Name
0   2013-02-08  NaN     NaN     14.63   14.75   8407500     AAL
1   2013-02-11  14.89   NaN	    14.26   14.46   8882000     AAL
2   2013-02-12  14.45   14.51   ?       14.27   8126000     AAL
3   2013-02-13  14.30   14.94   14.25   14.66   10259500    AAL
4   2013-02-14  14.94   14.96   13.16   13.99   31879900    AAL    
</pre>

<p>As you can see, there are two values missing from the first row of data and one from the second row. In addition, the third data row has a question mark in one of the entries. How do we deal with this?</p>

<p>The missing values were read in as “Not a Number” (NaN) by pandas as we would expect, so there is nothing further required from us for these values. However, pandas does not know what to do with the question mark indicating a missing value. To rectify this situation, we can pass a list of values to be considered missing values in a list to the <code>na_values</code> option.</p>

<pre class="prettyprint">
stocks_df = pd.read_csv('stocks_missing_data.csv', na_values=['?'])
stocks_df.head() 
</pre>

<pre class="prettyprint">
    date        open    high    low     close   volume      Name
0   2013-02-08  NaN     NaN     14.63   14.75   8407500     AAL
1   2013-02-11  14.89   NaN     14.26   14.46   8882000     AAL
2   2013-02-12  14.45   14.51   NaN     14.27   8126000     AAL
3   2013-02-13  14.30   14.94   14.25   14.66   10259500    AAL
4   2013-02-14  14.94   14.96   13.16   13.99   31879900    AAL    
</pre>

</p>Now the question mark has been read in as a NaN.</p>

<h1>Further Reading</h1>
<p>The <code>read_csv</code> command is highly flexible, with many, many options. To further explore these options, refer to the <a href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html" target="_blank">documentation</a>.</p>

</article>
</section>

<!--- Script Source Files --->
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
<html>